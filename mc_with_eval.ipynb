{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import markovify\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from ChordLanguageModel import ChordLanguageModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHAIN_ORDER = 3\n",
    "N_CANDIDATES = 50000\n",
    "N_BARS = 8\n",
    "DATA_PATH = \"chords3.csv\"\n",
    "rnn_config = {\n",
    "    \"HIDDEN_DIM\": 100,\n",
    "    \"EMBED_DIM\": 250,\n",
    "    \"DROPOUT\": 0.1,\n",
    "    \"L2\": 0.0005,\n",
    "    \"LEARNING_RATE\": 0.001,\n",
    "    \"BATCH_SIZE\": 16,\n",
    "    \"N_LAYERS\": 1,\n",
    "    \"N_EPOCHS\" :70\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784\n",
      "197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lauri/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:57: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0: tensor(256.0971, grad_fn=<AddBackward0>)\n",
      "TEST LOSS: tensor(4.2264)\n",
      "EPOCH 1: tensor(196.4226, grad_fn=<AddBackward0>)\n",
      "TEST LOSS: tensor(3.9353)\n",
      "EPOCH 2: tensor(184.4800, grad_fn=<AddBackward0>)\n",
      "TEST LOSS: tensor(3.7604)\n",
      "EPOCH 3: tensor(176.0550, grad_fn=<AddBackward0>)\n",
      "TEST LOSS: tensor(3.6333)\n",
      "EPOCH 4: tensor(169.4529, grad_fn=<AddBackward0>)\n",
      "TEST LOSS: tensor(3.5435)\n",
      "EPOCH 5: tensor(164.1537, grad_fn=<AddBackward0>)\n",
      "TEST LOSS: tensor(3.4712)\n",
      "EPOCH 6: tensor(160.0799, grad_fn=<AddBackward0>)\n",
      "TEST LOSS: tensor(3.4157)\n",
      "EPOCH 7: tensor(156.6096, grad_fn=<AddBackward0>)\n",
      "TEST LOSS: tensor(3.3748)\n",
      "EPOCH 8: tensor(153.8892, grad_fn=<AddBackward0>)\n",
      "TEST LOSS: tensor(3.3446)\n",
      "EPOCH 9: tensor(150.5749, grad_fn=<AddBackward0>)\n",
      "TEST LOSS: tensor(3.3085)\n",
      "EPOCH 10: tensor(148.2274, grad_fn=<AddBackward0>)\n",
      "TEST LOSS: tensor(3.2845)\n",
      "EPOCH 11: tensor(145.8311, grad_fn=<AddBackward0>)\n",
      "TEST LOSS: tensor(3.2589)\n",
      "EPOCH 12: tensor(144.2097, grad_fn=<AddBackward0>)\n",
      "TEST LOSS: tensor(3.2520)\n",
      "EPOCH 13: tensor(141.8262, grad_fn=<AddBackward0>)\n",
      "TEST LOSS: tensor(3.2250)\n",
      "EPOCH 14: tensor(140.2599, grad_fn=<AddBackward0>)\n",
      "TEST LOSS: tensor(3.2180)\n",
      "EPOCH 15: tensor(138.9178, grad_fn=<AddBackward0>)\n",
      "TEST LOSS: tensor(3.2129)\n",
      "EPOCH 16: tensor(137.2557, grad_fn=<AddBackward0>)\n",
      "TEST LOSS: tensor(3.1934)\n",
      "EPOCH 17: tensor(135.5650, grad_fn=<AddBackward0>)\n",
      "TEST LOSS: tensor(3.2066)\n",
      "EPOCH 18: tensor(134.6670, grad_fn=<AddBackward0>)\n",
      "TEST LOSS: tensor(3.1847)\n",
      "EPOCH 19: tensor(132.7981, grad_fn=<AddBackward0>)\n",
      "TEST LOSS: tensor(3.1859)\n",
      "EPOCH 20: tensor(131.9716, grad_fn=<AddBackward0>)\n",
      "TEST LOSS: tensor(3.1808)\n",
      "EPOCH 21: tensor(131.0268, grad_fn=<AddBackward0>)\n",
      "TEST LOSS: tensor(3.1852)\n",
      "EPOCH 22: tensor(129.8260, grad_fn=<AddBackward0>)\n",
      "TEST LOSS: tensor(3.1676)\n",
      "EPOCH 23: tensor(129.0274, grad_fn=<AddBackward0>)\n",
      "TEST LOSS: tensor(3.1737)\n",
      "EPOCH 24: tensor(128.3371, grad_fn=<AddBackward0>)\n",
      "TEST LOSS: tensor(3.1707)\n",
      "EPOCH 25: tensor(127.6773, grad_fn=<AddBackward0>)\n",
      "TEST LOSS: tensor(3.1577)\n",
      "EPOCH 26: tensor(126.3688, grad_fn=<AddBackward0>)\n",
      "TEST LOSS: tensor(3.1580)\n",
      "EPOCH 27: tensor(125.6524, grad_fn=<AddBackward0>)\n",
      "TEST LOSS: tensor(3.1551)\n",
      "EPOCH 28: tensor(125.2035, grad_fn=<AddBackward0>)\n",
      "TEST LOSS: tensor(3.1602)\n",
      "EPOCH 29: tensor(125.0517, grad_fn=<AddBackward0>)\n",
      "TEST LOSS: tensor(3.1489)\n",
      "EPOCH 30: tensor(124.0597, grad_fn=<AddBackward0>)\n",
      "TEST LOSS: tensor(3.1558)\n",
      "EPOCH 31: tensor(123.0871, grad_fn=<AddBackward0>)\n",
      "TEST LOSS: tensor(3.1481)\n",
      "EPOCH 32: tensor(122.8423, grad_fn=<AddBackward0>)\n",
      "TEST LOSS: tensor(3.1593)\n",
      "EPOCH 33: tensor(123.0915, grad_fn=<AddBackward0>)\n",
      "TEST LOSS: tensor(3.1532)\n",
      "EPOCH 34: tensor(122.4604, grad_fn=<AddBackward0>)\n",
      "TEST LOSS: tensor(3.1502)\n",
      "EPOCH 35: tensor(121.3847, grad_fn=<AddBackward0>)\n",
      "TEST LOSS: tensor(3.1516)\n",
      "EPOCH 36: tensor(122.0737, grad_fn=<AddBackward0>)\n",
      "TEST LOSS: tensor(3.1610)\n",
      "EPOCH 37: tensor(121.6427, grad_fn=<AddBackward0>)\n",
      "TEST LOSS: tensor(3.1510)\n",
      "EPOCH 38: tensor(120.7599, grad_fn=<AddBackward0>)\n",
      "TEST LOSS: tensor(3.1564)\n",
      "EPOCH 39: tensor(120.4740, grad_fn=<AddBackward0>)\n",
      "TEST LOSS: tensor(3.1547)\n",
      "EPOCH 40: tensor(119.8652, grad_fn=<AddBackward0>)\n",
      "TEST LOSS: tensor(3.1389)\n",
      "EPOCH 41: tensor(119.3365, grad_fn=<AddBackward0>)\n",
      "TEST LOSS: tensor(3.1459)\n",
      "EPOCH 42: tensor(119.0024, grad_fn=<AddBackward0>)\n",
      "TEST LOSS: tensor(3.1648)\n",
      "EPOCH 43: tensor(118.6688, grad_fn=<AddBackward0>)\n",
      "TEST LOSS: tensor(3.1491)\n",
      "EPOCH 44: tensor(118.4522, grad_fn=<AddBackward0>)\n",
      "TEST LOSS: tensor(3.1508)\n",
      "EPOCH 45: tensor(118.2145, grad_fn=<AddBackward0>)\n",
      "TEST LOSS: tensor(3.1601)\n",
      "EPOCH 46: tensor(117.7600, grad_fn=<AddBackward0>)\n",
      "TEST LOSS: tensor(3.1592)\n",
      "EPOCH 47: tensor(117.8671, grad_fn=<AddBackward0>)\n",
      "TEST LOSS: tensor(3.1545)\n",
      "EPOCH 48: tensor(116.9483, grad_fn=<AddBackward0>)\n",
      "TEST LOSS: tensor(3.1681)\n",
      "EPOCH 49: tensor(116.3626, grad_fn=<AddBackward0>)\n",
      "TEST LOSS: tensor(3.1563)\n",
      "EPOCH 50: tensor(116.5085, grad_fn=<AddBackward0>)\n",
      "TEST LOSS: tensor(3.1670)\n",
      "EPOCH 51: tensor(116.2338, grad_fn=<AddBackward0>)\n",
      "TEST LOSS: tensor(3.1738)\n",
      "EPOCH 52: tensor(116.9612, grad_fn=<AddBackward0>)\n",
      "TEST LOSS: tensor(3.1621)\n",
      "EPOCH 53: tensor(116.4205, grad_fn=<AddBackward0>)\n",
      "TEST LOSS: tensor(3.1576)\n",
      "EPOCH 54: tensor(116.2628, grad_fn=<AddBackward0>)\n",
      "TEST LOSS: tensor(3.1655)\n",
      "EPOCH 55: tensor(115.6818, grad_fn=<AddBackward0>)\n",
      "TEST LOSS: tensor(3.1717)\n",
      "EPOCH 56: tensor(114.9188, grad_fn=<AddBackward0>)\n",
      "TEST LOSS: tensor(3.1647)\n",
      "EPOCH 57: tensor(116.4057, grad_fn=<AddBackward0>)\n",
      "TEST LOSS: tensor(3.1614)\n",
      "EPOCH 58: tensor(114.9599, grad_fn=<AddBackward0>)\n",
      "TEST LOSS: tensor(3.1784)\n",
      "EPOCH 59: tensor(115.0267, grad_fn=<AddBackward0>)\n",
      "TEST LOSS: tensor(3.1615)\n",
      "EPOCH 60: tensor(113.9439, grad_fn=<AddBackward0>)\n",
      "TEST LOSS: tensor(3.1669)\n",
      "EPOCH 61: tensor(113.0007, grad_fn=<AddBackward0>)\n",
      "TEST LOSS: tensor(3.1800)\n",
      "EPOCH 62: tensor(113.7403, grad_fn=<AddBackward0>)\n",
      "TEST LOSS: tensor(3.1696)\n",
      "EPOCH 63: tensor(114.1641, grad_fn=<AddBackward0>)\n",
      "TEST LOSS: tensor(3.1830)\n",
      "EPOCH 64: tensor(113.3643, grad_fn=<AddBackward0>)\n",
      "TEST LOSS: tensor(3.1821)\n",
      "EPOCH 65: tensor(112.5365, grad_fn=<AddBackward0>)\n",
      "TEST LOSS: tensor(3.1789)\n",
      "EPOCH 66: tensor(112.1253, grad_fn=<AddBackward0>)\n",
      "TEST LOSS: tensor(3.1842)\n",
      "EPOCH 67: tensor(112.2765, grad_fn=<AddBackward0>)\n",
      "TEST LOSS: tensor(3.1908)\n",
      "EPOCH 68: tensor(112.4705, grad_fn=<AddBackward0>)\n",
      "TEST LOSS: tensor(3.1812)\n",
      "EPOCH 69: tensor(113.6056, grad_fn=<AddBackward0>)\n",
      "TEST LOSS: tensor(3.1955)\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "clm = ChordLanguageModel(DATA_PATH)\n",
    "clm.train_model(rnn_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_PATH)\n",
    "df.chords = df.chords.apply(lambda x: eval(x))\n",
    "mc_data = df.chords.to_numpy().tolist()\n",
    "mc = markovify.Chain(mc_data, state_size=CHAIN_ORDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_time(c):\n",
    "    bars = 0\n",
    "    time = 0\n",
    "    fail = False\n",
    "    for chord in c:\n",
    "        time += 1/int(chord[0])\n",
    "        if time == 1:\n",
    "            bars = bars + 1\n",
    "            time = 0\n",
    "            continue\n",
    "        if time > 1:\n",
    "            fail = True\n",
    "            break\n",
    "    if not fail:\n",
    "        if bars == N_BARS:\n",
    "            return True\n",
    "    else:\n",
    "        return False\n",
    "def validate_walk_length(c):\n",
    "    if len(c) == N_BARS:\n",
    "        return True\n",
    "candidates = []\n",
    "for i in range(N_CANDIDATES):\n",
    "    c = mc.walk()\n",
    "    candidates.append(c)\n",
    "accepted = []\n",
    "for candidate in candidates:\n",
    "    if validate_walk_length(candidate):\n",
    "        accepted.append(candidate)\n",
    "accepted = [[c[1] for c in cp] for cp in accepted]\n",
    "#accepted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = clm.evaluate(accepted)\n",
    "#scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['Dm7', 'G7', 'Cmaj7', 'Dm7', 'G7', 'C6', 'Dm7', 'G7'], -20.051342010498047),\n",
       " (['D7', 'Dm7', 'G7', 'Dm7', 'G7', 'C6', 'Dm7', 'G7'], -20.066665649414062),\n",
       " (['Dbm', 'A7', 'Dm7', 'G7', 'Em7', 'A7', 'Dm7', 'G7'], -20.22988510131836),\n",
       " (['Cmaj7', 'Am7', 'Dm7', 'G7', 'Cmaj7', 'Am7', 'Dm7', 'G7'],\n",
       "  -20.39394760131836),\n",
       " (['Cmaj7', 'Am7', 'Dm7', 'G7', 'Cmaj7', 'Am7', 'Dm7', 'G7'],\n",
       "  -20.39394760131836),\n",
       " (['Cmaj7', 'Am7', 'Dm7', 'G7', 'Cmaj7', 'Am7', 'Dm7', 'G7'],\n",
       "  -20.39394760131836),\n",
       " (['Cmaj7', 'Am7', 'Dm7', 'G7', 'Cmaj7', 'Am7', 'Dm7', 'G7'],\n",
       "  -20.39394760131836),\n",
       " (['Cm', 'Cm', 'Cm', 'Cm', 'Cm', 'Cm', 'Cm', 'Cm'], -20.419933319091797),\n",
       " (['Cm', 'Cm', 'Cm', 'Cm', 'Cm', 'Cm', 'Cm', 'Cm'], -20.419933319091797),\n",
       " (['Cmaj7', 'Dm7', 'G7', 'Dm7', 'G7', 'C6', 'Dm7', 'G7'], -20.93349266052246),\n",
       " (['Cmaj7', 'Dm7', 'G7', 'Dm7', 'G7', 'C6', 'Dm7', 'G7'], -20.93349266052246),\n",
       " (['Dm7', 'G7', 'Em7', 'A7', 'Dm7', 'G7', 'C6', 'C6'], -21.1406192779541),\n",
       " (['Dm7', 'G7', 'Dm7', 'G7', 'Dm7', 'G7', 'C6', 'C6'], -21.244298934936523),\n",
       " (['C6', 'Bm7', 'A7', 'Dm7', 'G7', 'C6', 'Dm7', 'G7'], -21.285099029541016),\n",
       " (['Dm7', 'G7', 'Dm7', 'G7', 'Dm7', 'G7', 'Dm7', 'G7'], -21.34994888305664),\n",
       " (['C6', 'Am7', 'Dm7', 'G7', 'C6', 'Am7', 'Dm7', 'G7'], -21.37795639038086),\n",
       " (['C6', 'Am7', 'Dm7', 'G7', 'C6', 'Am7', 'Dm7', 'G7'], -21.37795639038086),\n",
       " (['Dm7', 'G7', 'Dm7', 'G7', 'Dm7', 'G7', 'Cmaj7', 'Cmaj7'],\n",
       "  -21.39531135559082),\n",
       " (['Cmaj7', 'Am7', 'Dm7', 'G7', 'Em7', 'A7', 'Dm7', 'G7'],\n",
       "  -21.606346130371094),\n",
       " (['Cmaj7', 'Am7', 'Dm7', 'G7', 'Em7', 'A7', 'Dm7', 'G7'],\n",
       "  -21.606346130371094)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scored = []\n",
    "for i in range(len(accepted)):\n",
    "    scored.append((accepted[i], scores[i]))\n",
    "scored.sort(key=lambda x: x[1], reverse=True)\n",
    "best = scored[:20]\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*args, **kw)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(scores, bins = 50)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
